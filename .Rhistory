tokenize_words(a, lowercase = F, stopwords = ',')
subjects <- tokenize_words(html_text(html_nodes(h, '.list-subjects')))
subjects
subjects[1]
subjects[1:5]
read_html
css
html
page
page
?page
h
m = get_css(h, '.meta')
get_css <- function(h, css)
tokenize_words(html_text(html_nodes(h, css)))
get_css <- function(h, css)
tokenize_words(html_text(html_nodes(h, css)))
m = get_css(h, '.meta')
str(m)
length(m)
typeof(m)
m[[1]]
text
tokenize
get_css <- function(h, css, tokenize=TRUE) {
ht <- html_text(html_nodes(h, css))
if(tokenize) tokenize_words(ht) else ht
}
m = get_css(h, '.meta', F)
str(m)
typeof(m)
m[1]
m = get_css(h, 'dl dd', F)
m[1]
m1 = get_css(h, 'dl dd', F)
m2 = get_css(h, '.meta', F)
m1[1] == m2[1]
m1[1]
m2[1]
m2[1]
m1[1] == m2[1]
m1[1]
m1[1] == paste0('\n',m2[1])
paste0('\n',m2[1])
m1[1]
m1[1] == paste0('\n',m2[1],'\n')
url <- paste0('https://arxiv.org/list/', category, '/new')
h <- read_html(url)
id <- get_css(h, '.list-identifier')
id
type
type <- as.character(lapply(get_css(h, '.list-identifier'), function(x) {
if('cross' %in% x ) 'cross-list'
else if('replaced' %in% x) 'replacement' else 'new'
}))
type
title_abs <- get_css(h, '.mathjax')
title_abs[1]
title_abs[2]
first
which(type == 'replacement')
length(title_abs)
sum(type != 'replacement')
30*2 + sum(type == 'replacement')
length(title_abs)
strsplit
strsplit('a.bel', '.')
stringr::str_split('a.bel', '.')
stringi::stri_split('a.bel', '.')
stringr::str_split('a.bel', '[.]')
strsplit('a.bel', '[.]')
strsplit('a.bel,', '[.,]')
strsplit('a.bel,a', '[.,]')
authors <- get_css(h, '.list-authors', F)
authors
strsplit(authors, '[\n]')
strsplit(authors, '[\n,]')
length(authors)
strsplit(authors, '[\n,]')
c('a', 'b') %in% c('a', 'b', 'c')
c('a', 'b', 'c') %in% c('a', 'b')
authors[56]
authors[[56]]
authors[56]
strsplit(authors, '[\n,]')
strsplit(authors, '[\n,]')[56]
strsplit(authors, '[\n,]')[56][2]
strsplit(authors, '[\n,]')[[56]]
strsplit(authors, '[\n,]')[[56]][2]
strsplit(authors, '[\n,]')[[56]][2] == 'Authors: '
strsplit(authors, '[\n,]')[[56]][2] == 'Authors:  '
for(i in 1:56) strsplit(authors, '[\n,]')[[i]][1:2]
for(i in 1:56) print(strsplit(authors, '[\n,]')[[i]][1:2])
authors <- strsplit(get_css(h, '.list-authors', F), '[\n,]')
authors
authors <- authors[!(authors %in% c('', ' ', 'Authors: '))]
authors
type <- get_css(h, '.list-identifier')
type <- as.character(lapply(type, function(x) {
if('cross' %in% x ) 'cross-list'
else if('replaced' %in% x) 'replacement' else 'new'
}))
type
?match.arg
first_replacement <- which(type == 'replacement')[1]
title_abs <- get_css(h, '.mathjax')
title_abs[1]
title_abs[2]
seq(2, 11, 2)
first_replacement
title_abs[seq(2, first_replacement, 2)]
seq(2, first_replacement, 2)
stopwords()
paste(c('a', 'b'))
get_css <- function(h, css, tokenize=TRUE, ...) {
ht <- html_text(html_nodes(h, css))
if(tokenize) tokenize_words(ht, ...) else ht
}
title_abs <- get_css(h, '.mathjax', stopwords = stopwords())
title_abs
abs <- title_abs[seq(2, first_replacement, 2)]
abs
abs <- vector('list', N)
abs <- title_abs[seq(2, first_replacement, 2)]
N <- length(type)
abs <- vector('list', N)
abs
abs[1:(first_replacement-1)] <- title_abs[seq(2, first_replacement, 2)]
abs
stopwords()
rm(title_abs)
titles_abs <- get_css(h, '.mathjax', stopwords = stopwords())
abs <- vector('list', N)
abs[1:(first_replacement-1)] <- titles_abs[seq(2, first_replacement, 2)]
abs
seq(1, first_replacement, 2)
seq(1, first_replacement-1, 2)
seq(first_replacement, N)
titles <- c(titles_abs[seq(1, first_replacement-1, 2)],
titles_abs[seq(first_replacement, N)])
titles
titles_abs[seq(1, first_replacement-1, 2)]
N
titles <- c(titles_abs[seq(1, first_replacement-1, 2)],
titles_abs[seq(first_replacement, length(titles_abs))])
titles
titles <- c(titles_abs[seq(1, first_replacement-1, 2)],
titles_abs[seq(2*first_replacement-1, length(titles_abs))])
titles
titles_abs
first_replacement
2*first_replacement-1
length(titles_abs)
seq(1, first_replacement-1, 2)
length(seq(1, first_replacement-1, 2))
seq(2*first_replacement-1, length(titles_abs))
length(seq(2*first_replacement-1, length(titles_abs)))
26 + 15
seq(1, first_replacement-1, 2)
seq(1, 2*first_replacement, 2)
seq(1, 2*first_replacement-1, 2)
seq(1, 2*(first_replacement-1), 2)
length(seq(1, 2*(first_replacement-1), 2))
seq(2*first_replacement-1, length(titles_abs))
length(seq(2*first_replacement-1, length(titles_abs)))
56
titles <- c(titles_abs[seq(1, 2*(first_replacement-1), 2)],
titles_abs[seq(2*first_replacement-1, length(titles_abs))])
titles
for(tt in titles) print(tt[1])
lapply(titles_abs, function(x) x[1] == 'title')
titles_abs[lapply(titles_abs, function(x) x[1] == 'title')]
titles_abs[as.logical(lapply(titles_abs, function(x) x[1] == 'title'))]
titles_abs <- html_text(html_nodes(h, '.mathjax'))
titles_abs
titles_abs <- get_css(h, '.mathjax', lowercase=F, stopwords = stopwords())
titles_abs
replace
library(magrittr)
type <- get_css(h, '.list-identifier') %>%
lapply(function(x) {
if('cross' %in% x ) 'cross-list'
else if('replaced' %in% x) 'replacement' else 'new'
}) %>% as.character()
type
detach("package:magrittr", unload=TRUE)
library("magrittr", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.4")
library(dplyr)
matrix(1:9, 3)[[1]]
matrix(1:9, 3)[1]
matrix(1:9, 3) %>% str
titles <- c(titles_abs[seq(1, 2*(first_replace-1), 2)],
titles_abs[seq(2*first_replace-1, length(titles_abs))])
first_replace <- which(type == 'replacement')[1]
titles <- c(titles_abs[seq(1, 2*(first_replace-1), 2)],
titles_abs[seq(2*first_replace-1, length(titles_abs))])
titles
titles <- lapply(c(titles_abs[seq(1, 2*(first_replace-1), 2)],
titles_abs[seq(2*first_replace-1, length(titles_abs))]),
function(x) x[-1])
titles
titles_abs <- get_css(h, '.mathjax')
abs <- vector('list', N)
abs[1:(first_replace-1)] <- titles_abs[seq(2, first_replace, 2)]
abs
titles <- lapply(c(titles_abs[seq(1, 2*(first_replace-1), 2)],
titles_abs[seq(2*first_replace-1, length(titles_abs))]),
function(x) x[-1])
titles
authors <- strsplit(get_css(h, '.list-authors', F), '[\n,]')
authors
authors <- lapply(strsplit(get_css(h, '.list-authors', F), '[\n,]'),
function(x) x[! x %in% c('', ' ', 'Authors: ')])
authors
subjects <- get_css(h, '.list-subjects')
subjects
subjects <- lapply(get_css(h, '.list-subjects'), function(x) x[-1])
subjects
subjects <- get_css(h, '.list-subjects', tokenize = FALSE)
subjects
strsplit(get_css(h, '.list-subjects', tokenize = FALSE), '[\n:;]')
strsplit(get_css(h, '.list-subjects', tokenize = FALSE), '[\n:;\ ]')
strsplit(get_css(h, '.list-subjects', tokenize = FALSE), '[\n:;]')
strsplit(get_css(h, '.list-subjects', tokenize = F), '[\n:;]')
subjects <- get_css(h, '.list-subjects')
subjects
grep('[.]', c('abel', 'a.bel'))
?grep
grep('[.]', c('abel', 'a.bel'), value=FALSE)
grep('[.]', c('abel', 'a.bel'), value=TRUE)
grep('[.]', c('abel', 'a.bel', 'borges', '.borges'), value=TRUE)
subjects <- lapply(get_css(h, '.list-subjects'),
function(x) grep('[.]', x[-1]))
subjects
subjects <- lapply(get_css(h, '.list-subjects'),
function(x) grep('[.]', x[-1], value = TRUE))
subjects
comments <- get_css(h, '.list-comments')
comments
rm(list=ls())
library(rvest)
library(tokenizers)
categories <- c('stat', 'math', 'physics', 'cs', 'q-bio', 'q-fin')
get_css <- function(h, css, tokenize = TRUE, ...) {
ht <- html_text(html_nodes(h, css))
if(tokenize) tokenize_words(ht, stopwords = stopwords(), ...) else ht
}
get_arxiv_today_html <- function(category = categories) {
url <- paste0('https://arxiv.org/list/', match.arg(category), '/new')
read_html(url)
}
h <- get_arxiv_today_html('stat')
h
get_arxiv_html_now <- function(category = categories) {
url <- paste0('https://arxiv.org/list/', match.arg(category), '/new')
read_html(url)
}
h <- get_arxiv_html_now('stat')
h
get_arxiv_now <- function(h) {
type <- as.character(lapply(get_css(h, '.list-identifier'), function(x) {
if('cross' %in% x ) 'cross-list'
else if('replaced' %in% x) 'replacement' else 'new'
}))
first_replace <- which(type == 'replacement')[1]
titles_abs <- get_css(h, '.mathjax')
abs <- vector('list', length(type))
abs[1:(first_replace-1)] <- titles_abs[seq(2, first_replace, 2)]
titles <- lapply(c(titles_abs[seq(1, 2*(first_replace-1), 2)],
titles_abs[seq(2*first_replace-1, length(titles_abs))]),
function(x) x[-1])
authors <- lapply(strsplit(get_css(h, '.list-authors', F), '[\n,]'),
function(x) x[! x %in% c('', ' ', 'Authors: ')])
subjects <- lapply(get_css(h, '.list-subjects'),
function(x) grep('[.]', x[-1], value = TRUE))
# comments <- get_css(h, '.list-comments')
list(
type = type,
titles = titles,
abs = abs,
authors = authors,
subjects = subjects
)
}
a <- get_arxiv_now(h)
a
names(a)
for(i in seq_along(a)) print(length(a[[i]]))
a[[1]]
a$titles
a$abs
a$authors
a$subjects
a$abs
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords)) counts[i] <- sum(keyword == arxiv)
counts / sum(counts)
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords)) counts[i] <- sum(keywords[i] == arxiv)
counts / sum(counts)
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords)) counts[i] <- sum(keywords[[i]] == arxiv)
counts / sum(counts)
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning
a$abs
sum(list(1,2,3))
do.call(sum, list(1,2,3))
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords))
counts[i] <- do.call(sum, lapply(arxiv, function(x) keywords[i] == x))
counts / sum(counts)
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning
sum(learning)
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords))
counts[i] <- do.call(sum, lapply(arxiv, function(x) keywords[i] == x))
list(absolute = counts, relative = counts / sum(counts))
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords)) {
print(lapply(arxiv, function(x) keywords[i] == x))
counts[i] <- do.call(sum, lapply(arxiv, function(x) keywords[i] == x))
}
list(absolute = counts, relative = counts / sum(counts))
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
a$abs
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning <- keyword_counts(c('learning', 'deep', 'neural'), a$abs)
learning
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network', 'model'), a$abs)
learning
keyword_counts <- function(keywords, arxiv) {
counts <- numeric(length(keywords))
for(i in seq_along(keywords))
counts[i] <- do.call(sum, lapply(arxiv, function(x) keywords[i] == x))
list(absolute = counts, relative = counts / sum(counts))
}
learning <- keyword_counts(c('learning', 'deep', 'neural', 'network'), a$abs)
learning
one_of
?one_of
??one_of
setwd('~/apdmbj1@de.ufpe.br/stallings/')
one_of
dplyr::one_of
n()
dplyr::n
dplyr::n()
rm(list=ls())
setwd('~/Documents/sideprojs/cPCAr/')
# Synthetic data from Appendix A of the paper
source('./cPCA.R')
source('./multiplot.R')
library(ggplot2)
X_red <- cbind(matrix(rnorm(20*100), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_blue <- cbind(matrix(rnorm(10*100), nrow=100),
matrix(rnorm(10*100, mean=3), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_yellow <- cbind(matrix(rnorm(10*100, mean=6), nrow=100),
matrix(rnorm(10*100), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_black <- cbind(matrix(rnorm(10*100, mean=6), nrow=100),
matrix(rnorm(10*100, mean=3), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X <- rbind(X_red, X_blue, X_yellow, X_black)
Y <- cbind(matrix(rnorm(10*400, sd=sqrt(3)), nrow=400),
matrix(rnorm(10*400), nrow=400),
matrix(rnorm(10*400, sd=sqrt(10)), nrow=400))
groups <- c('red', 'blue', 'yellow', 'black')
alphas <- c(0, 0.7, 2.7, 119.4)
gg <- vector('list', length(alphas))
for(i in seq_along(alphas)) {
cPC_2d <- X %*% cPCA_alpha(X, Y, alphas[i], 2)
df <- data.frame(cPC_2d, group=rep(groups, each=100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(alphas[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols=2)
# TODO: make auto-selection work
cpca <- cPCA(X, Y)
source('./dPCA.R')
# TODO: make auto-selection work
cpca <- cPCA(X, Y, 4)
cpca$alpha_star
str(cpca$V_star)
i
cpca$V_star[[i]]
# TODO: make auto-selection work
cpca <- cPCA(X, Y, 4)
for(i in seq_along(cpca$alpha_star)) {
cPC_2d <- X %*% cpca$V_star[[i]]
df <- data.frame(cPC_2d, group = rep(groups, each=100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(alphas[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols = 2)
for(i in seq_along(cpca$alpha_star)) {
cPC_2d <- X %*% cpca$V_star[[i]]
df <- data.frame(cPC_2d, group = rep(groups, each=100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(cpca$alpha_star[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols = 2)
cpca$alpha_star
make_viz <- function(alphas, Vs) {
gg <- vector('list', length(alphas))
for(i in seq_along(gg)) {
df <- data.frame(X %*% Vs[[i]], group = rep(groups, each = 100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(alphas[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols = 2)
}
# TODO: this results are different from the paper
groups <- c('red', 'blue', 'yellow', 'black')
# TODO: this results are different from the paper
alphas <- c(0, 0.7, 2.7, 119.4)
Vs <- vector('list', length(alphas))
for(i in seq_along(Vs)) Vs[[i]] <- cPCA_alpha(X, Y, alphas[i], 2)
make_viz(alphas, Vs, groups)
make_viz <- function(alphas, Vs, groups) {
gg <- vector('list', length(alphas))
for(i in seq_along(gg)) {
df <- data.frame(X %*% Vs[[i]], group = rep(groups, each = 100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(alphas[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols = 2)
}
make_viz(alphas, Vs, groups)
# TODO: make auto-selection work
cpca <- cPCA(X, Y, p = 4)
make_viz(cpca$alpha_star, cpca$V_star, groups)
# Synthetic data from Appendix A of the paper
source('./cPCA.R')
source('./dPCA.R')
source('./multiplot.R')
X_red <- cbind(matrix(rnorm(20*100), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_blue <- cbind(matrix(rnorm(10*100), nrow=100),
matrix(rnorm(10*100, mean=3), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_yellow <- cbind(matrix(rnorm(10*100, mean=6), nrow=100),
matrix(rnorm(10*100), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X_black <- cbind(matrix(rnorm(10*100, mean=6), nrow=100),
matrix(rnorm(10*100, mean=3), nrow=100),
matrix(rnorm(10*100, sd=sqrt(10)), nrow=100))
X <- rbind(X_red, X_blue, X_yellow, X_black)
Y <- cbind(matrix(rnorm(10*400, sd=sqrt(3)), nrow=400),
matrix(rnorm(10*400), nrow=400),
matrix(rnorm(10*400, sd=sqrt(10)), nrow=400))
make_viz <- function(alphas, Vs, groups) {
gg <- vector('list', length(alphas))
for(i in seq_along(gg)) {
df <- data.frame(X %*% Vs[[i]], group = rep(groups, each = 100))
gg[[i]] <- ggplot(df, aes(X1, X2, color = group)) +
geom_point() +
scale_color_manual(values = groups, labels = groups) +
ggtitle(bquote(alpha ~ '=' ~ .(alphas[i]))) +
labs(x = 'cPC1', y = 'cPC2')
}
multiplot(plotlist = gg, cols = 2)
}
groups <- c('red', 'blue', 'yellow', 'black')
# TODO: this results are different from the paper
alphas <- c(0, 0.7, 2.7, 119.4)
Vs <- vector('list', length(alphas))
for(i in seq_along(Vs)) Vs[[i]] <- cPCA_alpha(X, Y, alphas[i], 2)
make_viz(alphas, Vs, groups)
# TODO: make auto-selection work
cpca <- cPCA(X, Y, p = 4)
make_viz(cpca$alpha_star, cpca$V_star, groups)
rm(list=ls())
setwd('../arxiveR/')
# setwd() to arxiveR directory
s16 <- readRDS('./stat2016_up2aug.rds')
s17 <- readRDS('./stat2017.rds')
